{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.讀入需要的套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Layers for FNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "\n",
    "# Layers for CNN\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# For data preprocessing\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料前處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "name_list = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "idx = np.random.randint(x_train.shape[0])\n",
    "x_sample = x_train[idx]\n",
    "y_sample = y_train[idx].squeeze()\n",
    "plt.imshow(x_sample,'Greys')\n",
    "plt.title(name_list[y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape #檢測資料型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the range of featurs\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)/255 #色彩範圍為0到255所以要除於255\n",
    "x_test  = x_test.reshape(10000, 28, 28, 1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 建立CNN分類模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\maxwu\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "CNN_layers = [Conv2D(28, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(112, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(224, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=112, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x23e8cbc6e88>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x23e8cb1df48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x23e8cb20d48>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x23e8cb20588>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x23e8cb20048>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x23e84460308>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23e8cbc6e48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23e84454788>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_layers + FC_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 112)       28336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 224)         226016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 112)               25200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1130      \n",
      "=================================================================\n",
      "Total params: 280,962\n",
      "Trainable params: 280,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential(CNN_layers + FC_layers)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編譯模型: 設定模型訓練時的設定\n",
    "\n",
    "- Optimizer: Adam\n",
    "- Loss: categorical cross-entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=Adam(),\n",
    "              metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x23e8cbc6e88>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x23e8cb1df48>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x23e8cb20d48>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x23e8cb20588>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x23e8cb20048>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x23e84460308>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23e8cbc6e48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x23e84454788>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型: 透過訓練來學習分類資料的函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 113s 2ms/sample - loss: 0.8671 - categorical_accuracy: 0.6766 - val_loss: 0.6552 - val_categorical_accuracy: 0.7573\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.5808 - categorical_accuracy: 0.7871 - val_loss: 0.5506 - val_categorical_accuracy: 0.8028\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.4928 - categorical_accuracy: 0.8208 - val_loss: 0.4597 - val_categorical_accuracy: 0.8369\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e8a68ccc8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=112, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('CNN_one.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型預測: 預測資料集的準確率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 29s 489us/sample - loss: 0.4319 - categorical_accuracy: 0.8466\n",
      "10000/10000 [==============================] - 5s 494us/sample - loss: 0.4597 - categorical_accuracy: 0.8369\n",
      "Train Accuracy: 84.65999960899353\n",
      "Test Accuracy: 83.6899995803833\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('CNN_one.h5')\n",
    "\n",
    "score_train = model.evaluate(x_train, y_train)\n",
    "score_test = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(X_train.shape[0])\n",
    "X_sample = X_train[idx]\n",
    "Y_sample = Y_train[idx].squeeze()\n",
    "plt.imshow(X_sample,'Greys')\n",
    "plt.title([Y_sample])\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the range of featurs\n",
    "X_train = X_train.reshape(60000, 28, 28, 1)/255\n",
    "X_test  = X_test.reshape(10000, 28, 28, 1)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "Y_train = to_categorical(Y_train, 10)\n",
    "Y_test = to_categorical(Y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model for fashion_mnist\n",
    "```\n",
    "CNN_layers = [Conv2D(28, (3, 3), input_shape=(28, 28, 1), padding='same', activation='relu', name='Conv_1'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(112, (3, 3), padding='same', activation='relu', name='Conv_2'),\n",
    "              MaxPool2D(),\n",
    "              Conv2D(224, (3, 3), padding='same', activation='relu', name='Conv_3'),\n",
    "              GlobalAveragePooling2D()]\n",
    "\n",
    "FC_layers = [Dense(units=112, activation='relu'),\n",
    "             Dense(units=10, activation='softmax')]\n",
    "```\n",
    "\n",
    "CNN model for mnist\n",
    "```\n",
    "# From model for fashion_mnist  \n",
    "CNN_layers\n",
    "\n",
    "# New FC layers for mnist\n",
    "FC_layers_number = [Dense(units=56, activation='relu'),\n",
    "                   Dense(units=112, activation='relu'),\n",
    "                   Dense(units=10, activation='softmax')]\n",
    "```\n",
    "CNN_layers 是跟人家**借**來的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FC_layers_number = [Dense(units=56, activation='relu'),\n",
    "                   Dense(units=112, activation='relu'),\n",
    "                   Dense(units=10, activation='softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 112)       28336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 224)         226016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 56)                12600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 112)               6384      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1130      \n",
      "=================================================================\n",
      "Total params: 274,746\n",
      "Trainable params: 274,746\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_number = Sequential(CNN_layers+FC_layers_number)\n",
    "model_number.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 遷移學習的訓練方式\n",
    "* Fine-tune: 新資料集的樣本數夠多，整個模型重新訓練\n",
    "* Frozen: 當新資料集的樣本數不夠多，凍結借來的部分，只針對新建立的神經網路層訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frozen\n",
    "for layer in CNN_layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 112)       28336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 224)         226016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 56)                12600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 112)               6384      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1130      \n",
      "=================================================================\n",
      "Total params: 274,746\n",
      "Trainable params: 20,114\n",
      "Non-trainable params: 254,632\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_number.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 31s 523us/sample - loss: 0.8348 - categorical_accuracy: 0.7366 - val_loss: 0.4603 - val_categorical_accuracy: 0.8490\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 31s 511us/sample - loss: 0.3795 - categorical_accuracy: 0.8809 - val_loss: 0.3131 - val_categorical_accuracy: 0.9028\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 33s 545us/sample - loss: 0.3051 - categorical_accuracy: 0.9030 - val_loss: 0.3040 - val_categorical_accuracy: 0.9032\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 33s 548us/sample - loss: 0.2522 - categorical_accuracy: 0.9200 - val_loss: 0.2418 - val_categorical_accuracy: 0.9200\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 33s 551us/sample - loss: 0.2266 - categorical_accuracy: 0.9291 - val_loss: 0.2049 - val_categorical_accuracy: 0.9335\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 33s 552us/sample - loss: 0.2026 - categorical_accuracy: 0.9349 - val_loss: 0.2112 - val_categorical_accuracy: 0.9359\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 33s 556us/sample - loss: 0.1898 - categorical_accuracy: 0.9402 - val_loss: 0.1697 - val_categorical_accuracy: 0.9475\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 33s 550us/sample - loss: 0.1766 - categorical_accuracy: 0.9436 - val_loss: 0.1688 - val_categorical_accuracy: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23eaa0867c8>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_number.fit(X_train, Y_train, batch_size=101, epochs=8,  validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 借來的神經網路 (的權重) 會如何變化？Frozen 的場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 28s 460us/sample - loss: 0.4319 - categorical_accuracy: 0.8466\n",
      "10000/10000 [==============================] - 5s 462us/sample - loss: 0.4597 - categorical_accuracy: 0.8369 ETA: 1s\n",
      "Train Accuracy: 84.65999960899353\n",
      "Test Accuracy: 83.6899995803833\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(x_train, y_train)\n",
    "score_test = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可以看出來和先前一樣，沒有影響\n",
    "___\n",
    "### 借來的神經網路 (的權重) 會如何變化？Fine-tune 的場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in CNN_layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 28, 28, 28)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 28)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 14, 14, 112)       28336     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 112)         0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 7, 7, 224)         226016    \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 56)                12600     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 112)               6384      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                1130      \n",
      "=================================================================\n",
      "WARNING:tensorflow:Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "Total params: 20,114\n",
      "Trainable params: 20,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_number.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 119s 2ms/sample - loss: 0.2005 - categorical_accuracy: 0.9416 - val_loss: 0.0986 - val_categorical_accuracy: 0.9691\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.1095 - categorical_accuracy: 0.9661 - val_loss: 0.0887 - val_categorical_accuracy: 0.9712\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0846 - categorical_accuracy: 0.9736 - val_loss: 0.0710 - val_categorical_accuracy: 0.9775\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0677 - categorical_accuracy: 0.9786 - val_loss: 0.0467 - val_categorical_accuracy: 0.9851\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0584 - categorical_accuracy: 0.9816 - val_loss: 0.0446 - val_categorical_accuracy: 0.9851\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0521 - categorical_accuracy: 0.9836 - val_loss: 0.0638 - val_categorical_accuracy: 0.9809\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0431 - categorical_accuracy: 0.9865 - val_loss: 0.0443 - val_categorical_accuracy: 0.9856\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 107s 2ms/sample - loss: 0.0379 - categorical_accuracy: 0.9875 - val_loss: 0.0395 - val_categorical_accuracy: 0.9867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e8e81ac08>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_number.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['categorical_accuracy'])\n",
    "model_number.fit(X_train, Y_train, batch_size=101, epochs=8,  validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 31s 515us/sample - loss: 1.4862 - categorical_accuracy: 0.4261\n",
      "10000/10000 [==============================] - 6s 560us/sample - loss: 1.4968 - categorical_accuracy: 0.4224\n",
      "Train Accuracy: 42.614999413490295\n",
      "Test Accuracy: 42.239999771118164\n"
     ]
    }
   ],
   "source": [
    "score_train = model.evaluate(x_train, y_train)\n",
    "score_test = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(f'Train Accuracy: {score_train[1]*100}')\n",
    "print(f'Test Accuracy: {score_test[1]*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 和先前的不一樣，Fine-tune有影響，和Frozen真的不同 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## 5. 結論\n",
    "### Transfer Learning建模真的方便不少，另外Frozen和Fine-tune的訓練時間差了五倍之多，且準確程度相差不遠。如果在新樣本數不多的情況下，採用Frozen的訓練方式，確實更為適切。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
